{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c658d8d-e841-467c-8536-c333207c92aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      ProjectID                                    RequirementText _class_\n",
      "0             1  The system shall refresh the display every 60 ...      PE\n",
      "1             1  The application shall match the color of the s...      LF\n",
      "2             1  If projected  the data must be readable.  On a...      US\n",
      "3             1  The product shall be available during normal b...       A\n",
      "4             1  If projected  the data must be understandable....      US\n",
      "...         ...                                                ...     ...\n",
      "2052          9  The database may trade off fidelity through ca...      FT\n",
      "2053          9  The API shall have master topology replicating...      FT\n",
      "2054          9  The system must parse, filter, transform and s...      FT\n",
      "2055          9  The application shall employ real-user monitor...      FT\n",
      "2056          9  The software should apply graceful degradation...      FT\n",
      "\n",
      "[2057 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import arff as liacarff\n",
    "\n",
    "# 加载 ARFF 文件\n",
    "with open('PROMISE_DOSSPRE_OLD_3.arff', 'r') as f:\n",
    "    data_dict = liacarff.load(f)\n",
    "\n",
    "# 提取数据\n",
    "data = data_dict['data']\n",
    "\n",
    "# 转换为 DataFrame\n",
    "df = pd.DataFrame(data, columns=[attr[0] for attr in data_dict['attributes']])\n",
    "df['ProjectID'] = df['ProjectID'].astype(int)  # 将 ProjectID 列转换为整数类型\n",
    "\n",
    "# 显示 DataFrame\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "59f1598c-1b5e-42a4-bf9b-93507a98a49d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/li/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/li/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/li/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ProjectID                                    RequirementText _class_\n",
      "0          1  The system shall refresh the display every 60 ...      PE\n",
      "1          1  The application shall match the color of the s...      LF\n",
      "2          1  If projected the data must be readable On a 10...      US\n",
      "3          1  The product shall be available during normal b...       A\n",
      "4          1  If projected the data must be understandable O...      US\n"
     ]
    }
   ],
   "source": [
    "# DATA PREPROCESSING\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import re\n",
    "import string\n",
    "\n",
    "# 下载NLTK的停用词和词性标注器数据\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "# lower\n",
    "# df['RequirementText'] = df['RequirementText'].str.lower()\n",
    "\n",
    "# # Remove punctuation, leading and trailing spaces\n",
    "df['RequirementText'] = df['RequirementText'].apply(lambda x: re.sub(f\"[{re.escape(string.punctuation)}]\", \"\", x.strip()))\n",
    "\n",
    "# # 分词\n",
    "df['RequirementText'] = df['RequirementText'].apply(word_tokenize)\n",
    "\n",
    "# # stopwords\n",
    "# stop_words = set(stopwords.words('english'))\n",
    "# df['RequirementText'] = df['RequirementText'].apply(lambda x: [word for word in x if word not in stop_words])\n",
    "\n",
    "# # stemming\n",
    "# stemmer = PorterStemmer()\n",
    "# df['RequirementText'] = df['RequirementText'].apply(lambda x: [stemmer.stem(word) for word in x])\n",
    "\n",
    "# # lemmatization\n",
    "# lemmatizer = WordNetLemmatizer()\n",
    "# df['RequirementText'] = df['RequirementText'].apply(lambda x: [lemmatizer.lemmatize(word) for word in x])\n",
    "\n",
    "# # 合并词语为字符串\n",
    "df['RequirementText'] = df['RequirementText'].apply(lambda x: ' '.join(x))\n",
    "\n",
    "# Replace multiple spaces with a single space\n",
    "df['RequirementText'] = df['RequirementText'].apply(lambda x: re.sub(' +', ' ', x))\n",
    "\n",
    "# 移除整个列中每个字符串首尾的全部空格\n",
    "df['RequirementText'] = df['RequirementText'].str.strip()\n",
    "\n",
    "# 查看处理后的数据集\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2df99007-ddfa-4b3a-99b6-e0f687b55ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e3d7057a-3221-46a4-95e6-66a2af495211",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "y = df['_class_']\n",
    "X = df['RequirementText']\n",
    "\n",
    "# 假设 X 是特征，y 是目标变量（类别标签）\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "671deca6-85fe-4be4-ab09-3c1ee057bbf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "# 使用TfidfVectorizer进行转换\n",
    "ngram_range = (1,2)\n",
    "min_df = 0.01 # ignore terms that appear in less than 1% of the documents\n",
    "max_df = 0.8 # ignore terms that appear in more than 80% of the documents\n",
    "\n",
    "tfidf_vectorizer = CountVectorizer(encoding='utf-8',\n",
    "                        ngram_range=ngram_range,\n",
    "                        stop_words=None,\n",
    "                        lowercase=False,\n",
    "                        max_df=max_df,\n",
    "                        min_df=min_df)\n",
    "\n",
    "features_train = tfidf_vectorizer.fit_transform(X_train).toarray()\n",
    "labels_train = y_train\n",
    "features_test = tfidf_vectorizer.transform(X_test).toarray()\n",
    "labels_test = y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7165f44e-6a30-4d90-a751-2958bbbc34be",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-08 13:10:54.371526: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-12-08 13:10:54.603345: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-12-08 13:10:54.603513: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-12-08 13:10:54.623254: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-12-08 13:10:54.698140: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-12-08 13:10:56.937341: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "116/116 [==============================] - 1s 3ms/step - loss: 2.3282 - accuracy: 0.2080 - val_loss: 2.1814 - val_accuracy: 0.2864\n",
      "Epoch 2/100\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 2.0366 - accuracy: 0.3431 - val_loss: 1.9284 - val_accuracy: 0.4272\n",
      "Epoch 3/100\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1.7211 - accuracy: 0.4673 - val_loss: 1.6974 - val_accuracy: 0.5243\n",
      "Epoch 4/100\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1.4672 - accuracy: 0.5667 - val_loss: 1.5023 - val_accuracy: 0.5777\n",
      "Epoch 5/100\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1.2726 - accuracy: 0.6272 - val_loss: 1.3765 - val_accuracy: 0.5922\n",
      "Epoch 6/100\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 1.1339 - accuracy: 0.6623 - val_loss: 1.3063 - val_accuracy: 0.5922\n",
      "Epoch 7/100\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 1.0284 - accuracy: 0.6823 - val_loss: 1.2412 - val_accuracy: 0.6262\n",
      "Epoch 8/100\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.9412 - accuracy: 0.7207 - val_loss: 1.2147 - val_accuracy: 0.6359\n",
      "Epoch 9/100\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.8758 - accuracy: 0.7277 - val_loss: 1.1901 - val_accuracy: 0.6456\n",
      "Epoch 10/100\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.8187 - accuracy: 0.7477 - val_loss: 1.1909 - val_accuracy: 0.6553\n",
      "Epoch 11/100\n",
      "116/116 [==============================] - 0s 2ms/step - loss: 0.7695 - accuracy: 0.7655 - val_loss: 1.1893 - val_accuracy: 0.6553\n",
      "Epoch 12/100\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.7312 - accuracy: 0.7801 - val_loss: 1.2052 - val_accuracy: 0.6553\n",
      "Epoch 13/100\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.6912 - accuracy: 0.7931 - val_loss: 1.1916 - val_accuracy: 0.6748\n",
      "Epoch 14/100\n",
      "116/116 [==============================] - 0s 1ms/step - loss: 0.6560 - accuracy: 0.7963 - val_loss: 1.2016 - val_accuracy: 0.6553\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1893 - accuracy: 0.6553\n",
      "Test Accuracy: 0.655339777469635\n",
      "7/7 [==============================] - 0s 1ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.58      0.67        12\n",
      "           1       0.78      0.70      0.74        44\n",
      "           2       0.83      0.71      0.77         7\n",
      "           3       0.25      0.11      0.15         9\n",
      "           4       0.64      0.88      0.74        16\n",
      "           5       0.47      0.56      0.51        16\n",
      "           6       0.90      0.69      0.78        13\n",
      "           7       0.64      0.72      0.68        25\n",
      "           8       0.80      0.50      0.62         8\n",
      "           9       0.83      0.50      0.62        10\n",
      "          10       0.52      0.67      0.58        24\n",
      "          11       0.62      0.73      0.67        22\n",
      "\n",
      "    accuracy                           0.66       206\n",
      "   macro avg       0.67      0.61      0.63       206\n",
      "weighted avg       0.67      0.66      0.65       206\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "feature_names = tfidf_vectorizer.get_feature_names_out()\n",
    "input_dimension = len(feature_names)\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "labels_train_encoded = label_encoder.fit_transform(labels_train)\n",
    "labels_test_encoded = label_encoder.transform(labels_test)\n",
    "\n",
    "labels_train_one_hot = to_categorical(labels_train_encoded)\n",
    "labels_test_one_hot = to_categorical(labels_test_encoded)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(24, input_dim=input_dimension, activation='relu'))\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dense(12, activation='softmax'))\n",
    "\n",
    "# 创建 EarlyStopping 回调\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "\n",
    "# 编译模型\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# 训练模型，并使用 EarlyStopping 回调\n",
    "history = model.fit(features_train, labels_train_one_hot, epochs=100, batch_size=16, \n",
    "                    validation_data=(features_test, labels_test_one_hot),\n",
    "                    callbacks=[early_stopping])\n",
    "\n",
    "accuracy = model.evaluate(features_test, labels_test_one_hot)[1]\n",
    "print(\"Test Accuracy:\", accuracy)\n",
    "\n",
    "y_pred_prob = model.predict(features_test)\n",
    "y_pred = np.argmax(y_pred_prob, axis=1)\n",
    "\n",
    "report = classification_report(np.argmax(labels_test_one_hot, axis=1), y_pred)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0f0708dd-4660-4b4b-89de-eefd3792671b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 5 Complete [00h 00m 07s]\n",
      "val_accuracy: 0.6618122855822245\n",
      "\n",
      "Best val_accuracy So Far: 0.7055016160011292\n",
      "Total elapsed time: 00h 00m 35s\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0897 - accuracy: 0.7136\n",
      "Test Accuracy (Best Model): 0.7135922312736511\n",
      "7/7 [==============================] - 0s 2ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.67      0.76        12\n",
      "           1       0.83      0.66      0.73        44\n",
      "           2       1.00      0.71      0.83         7\n",
      "           3       0.86      0.67      0.75         9\n",
      "           4       0.58      0.88      0.70        16\n",
      "           5       0.59      0.62      0.61        16\n",
      "           6       0.75      0.69      0.72        13\n",
      "           7       0.62      0.80      0.70        25\n",
      "           8       0.56      0.62      0.59         8\n",
      "           9       0.90      0.90      0.90        10\n",
      "          10       0.71      0.71      0.71        24\n",
      "          11       0.68      0.68      0.68        22\n",
      "\n",
      "    accuracy                           0.71       206\n",
      "   macro avg       0.75      0.72      0.72       206\n",
      "weighted avg       0.73      0.71      0.72       206\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from kerastuner.tuners import RandomSearch\n",
    "from kerastuner.engine.hyperparameters import HyperParameters\n",
    "\n",
    "# 定义模型构建函数\n",
    "def build_model(hp):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units=hp.Int('units_1', min_value=8, max_value=512, step=8),\n",
    "                    activation='relu', input_dim=input_dimension))\n",
    "    model.add(Dense(units=hp.Int('units_2', min_value=8, max_value=512, step=8),\n",
    "                    activation='relu'))\n",
    "    model.add(Dense(12, activation='softmax'))\n",
    "    \n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# 创建 EarlyStopping 回调\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "\n",
    "# 创建调优器\n",
    "tuner = RandomSearch(\n",
    "    build_model,\n",
    "    objective='val_accuracy',\n",
    "    max_trials=5,  # 试验的次数\n",
    "    executions_per_trial=3,  # 每个试验运行的次数\n",
    "    directory='my_tuning_dir',  # 存储结果的目录\n",
    "    project_name='my_neural_network_tuning',\n",
    "    overwrite=True\n",
    ")\n",
    "\n",
    "# 运行调优\n",
    "tuner.search(features_train, labels_train_one_hot, epochs=100, batch_size=16, \n",
    "             validation_data=(features_test, labels_test_one_hot),\n",
    "             callbacks=[early_stopping])\n",
    "\n",
    "# 获取最佳模型\n",
    "best_model = tuner.get_best_models(num_models=1)[0]\n",
    "\n",
    "# 评估最佳模型\n",
    "accuracy = best_model.evaluate(features_test, labels_test_one_hot)[1]\n",
    "print(\"Test Accuracy (Best Model):\", accuracy)\n",
    "\n",
    "# 预测最佳模型的输出\n",
    "y_pred_prob = best_model.predict(features_test)\n",
    "y_pred = np.argmax(y_pred_prob, axis=1)\n",
    "\n",
    "# 输出分类报告\n",
    "report = classification_report(np.argmax(labels_test_one_hot, axis=1), y_pred)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b6dc9dd4-63b9-44da-a016-a972e7e6fa0a",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'The system shall maintain customer email information as a required part of customer profile'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mimblearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mover_sampling\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SMOTE\n\u001b[1;32m      2\u001b[0m smote \u001b[38;5;241m=\u001b[39m SMOTE(random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m X_resampled, y_resampled \u001b[38;5;241m=\u001b[39m \u001b[43msmote\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_resample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m features_train_resampled \u001b[38;5;241m=\u001b[39m tfidf_vectorizer\u001b[38;5;241m.\u001b[39mfit_transform(X_train_resampled)\u001b[38;5;241m.\u001b[39mtoarray()\n\u001b[1;32m      6\u001b[0m labels_train_resampled \u001b[38;5;241m=\u001b[39m y_train_resampled\n",
      "File \u001b[0;32m~/dsse/indi/indi/lib/python3.10/site-packages/imblearn/base.py:208\u001b[0m, in \u001b[0;36mBaseSampler.fit_resample\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    187\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Resample the dataset.\u001b[39;00m\n\u001b[1;32m    188\u001b[0m \n\u001b[1;32m    189\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[38;5;124;03m    The corresponding label of `X_resampled`.\u001b[39;00m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m--> 208\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_resample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/dsse/indi/indi/lib/python3.10/site-packages/imblearn/base.py:106\u001b[0m, in \u001b[0;36mSamplerMixin.fit_resample\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    104\u001b[0m check_classification_targets(y)\n\u001b[1;32m    105\u001b[0m arrays_transformer \u001b[38;5;241m=\u001b[39m ArraysTransformer(X, y)\n\u001b[0;32m--> 106\u001b[0m X, y, binarize_y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_X_y\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    108\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msampling_strategy_ \u001b[38;5;241m=\u001b[39m check_sampling_strategy(\n\u001b[1;32m    109\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msampling_strategy, y, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampling_type\n\u001b[1;32m    110\u001b[0m )\n\u001b[1;32m    112\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_resample(X, y)\n",
      "File \u001b[0;32m~/dsse/indi/indi/lib/python3.10/site-packages/imblearn/base.py:161\u001b[0m, in \u001b[0;36mBaseSampler._check_X_y\u001b[0;34m(self, X, y, accept_sparse)\u001b[0m\n\u001b[1;32m    159\u001b[0m     accept_sparse \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsr\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsc\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    160\u001b[0m y, binarize_y \u001b[38;5;241m=\u001b[39m check_target_type(y, indicate_one_vs_all\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m--> 161\u001b[0m X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_sparse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    162\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m X, y, binarize_y\n",
      "File \u001b[0;32m~/dsse/indi/indi/lib/python3.10/site-packages/sklearn/base.py:622\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[1;32m    620\u001b[0m         y \u001b[38;5;241m=\u001b[39m check_array(y, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_y_params)\n\u001b[1;32m    621\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 622\u001b[0m         X, y \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_X_y\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcheck_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    623\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[1;32m    625\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "File \u001b[0;32m~/dsse/indi/indi/lib/python3.10/site-packages/sklearn/utils/validation.py:1146\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m   1141\u001b[0m         estimator_name \u001b[38;5;241m=\u001b[39m _check_estimator_name(estimator)\n\u001b[1;32m   1142\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1143\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m requires y to be passed, but the target y is None\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1144\u001b[0m     )\n\u001b[0;32m-> 1146\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1147\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1148\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1149\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_large_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_large_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1150\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1151\u001b[0m \u001b[43m    \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1152\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1153\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1154\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_2d\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1155\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_nd\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_nd\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1156\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_min_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_min_samples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1157\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_min_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_min_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1158\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1159\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mX\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1160\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1162\u001b[0m y \u001b[38;5;241m=\u001b[39m _check_y(y, multi_output\u001b[38;5;241m=\u001b[39mmulti_output, y_numeric\u001b[38;5;241m=\u001b[39my_numeric, estimator\u001b[38;5;241m=\u001b[39mestimator)\n\u001b[1;32m   1164\u001b[0m check_consistent_length(X, y)\n",
      "File \u001b[0;32m~/dsse/indi/indi/lib/python3.10/site-packages/sklearn/utils/validation.py:915\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    913\u001b[0m         array \u001b[38;5;241m=\u001b[39m xp\u001b[38;5;241m.\u001b[39mastype(array, dtype, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    914\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 915\u001b[0m         array \u001b[38;5;241m=\u001b[39m \u001b[43m_asarray_with_order\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mxp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    916\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ComplexWarning \u001b[38;5;28;01mas\u001b[39;00m complex_warning:\n\u001b[1;32m    917\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    918\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mComplex data not supported\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(array)\n\u001b[1;32m    919\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcomplex_warning\u001b[39;00m\n",
      "File \u001b[0;32m~/dsse/indi/indi/lib/python3.10/site-packages/sklearn/utils/_array_api.py:380\u001b[0m, in \u001b[0;36m_asarray_with_order\u001b[0;34m(array, dtype, order, copy, xp)\u001b[0m\n\u001b[1;32m    378\u001b[0m     array \u001b[38;5;241m=\u001b[39m numpy\u001b[38;5;241m.\u001b[39marray(array, order\u001b[38;5;241m=\u001b[39morder, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[1;32m    379\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 380\u001b[0m     array \u001b[38;5;241m=\u001b[39m \u001b[43mnumpy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    382\u001b[0m \u001b[38;5;66;03m# At this point array is a NumPy ndarray. We convert it to an array\u001b[39;00m\n\u001b[1;32m    383\u001b[0m \u001b[38;5;66;03m# container that is consistent with the input's namespace.\u001b[39;00m\n\u001b[1;32m    384\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m xp\u001b[38;5;241m.\u001b[39masarray(array)\n",
      "File \u001b[0;32m~/dsse/indi/indi/lib/python3.10/site-packages/pandas/core/series.py:953\u001b[0m, in \u001b[0;36mSeries.__array__\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m    906\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    907\u001b[0m \u001b[38;5;124;03mReturn the values as a NumPy array.\u001b[39;00m\n\u001b[1;32m    908\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    950\u001b[0m \u001b[38;5;124;03m      dtype='datetime64[ns]')\u001b[39;00m\n\u001b[1;32m    951\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    952\u001b[0m values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values\n\u001b[0;32m--> 953\u001b[0m arr \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    954\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m using_copy_on_write() \u001b[38;5;129;01mand\u001b[39;00m astype_is_view(values\u001b[38;5;241m.\u001b[39mdtype, arr\u001b[38;5;241m.\u001b[39mdtype):\n\u001b[1;32m    955\u001b[0m     arr \u001b[38;5;241m=\u001b[39m arr\u001b[38;5;241m.\u001b[39mview()\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: 'The system shall maintain customer email information as a required part of customer profile'"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "features_train_resampled = tfidf_vectorizer.fit_transform(X_train_resampled).toarray()\n",
    "labels_train_resampled = y_train_resampled\n",
    "features_test_resampled = tfidf_vectorizer.transform(X_test_resampled).toarray()\n",
    "labels_test_resampled = y_test_resampled\n",
    "\n",
    "feature_names = tfidf_vectorizer.get_feature_names_out()\n",
    "input_dimension = len(feature_names)\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "labels_train_encoded_resampled = label_encoder.fit_transform(labels_train_resampled)\n",
    "labels_test_encoded_resampled = label_encoder.transform(labels_test_resampled)\n",
    "\n",
    "labels_train_one_hot_resampled = to_categorical(labels_train_encoded_resampled)\n",
    "labels_test_one_hot_resampled = to_categorical(labels_test_encoded_resampled)\n",
    "\n",
    "tuner.search(features_train_resampled, labels_train_one_hot_resampled, epochs=100, batch_size=16, \n",
    "             validation_data=(features_test_resampled, labels_test_one_hot),\n",
    "             callbacks=[early_stopping])\n",
    "\n",
    "# 获取最佳模型\n",
    "best_model = tuner.get_best_models(num_models=1)[0]\n",
    "\n",
    "# 评估最佳模型\n",
    "accuracy = best_model.evaluate(features_test, labels_test_one_hot)[1]\n",
    "print(\"Test Accuracy (Best Model):\", accuracy)\n",
    "\n",
    "# 预测最佳模型的输出\n",
    "y_pred_prob = best_model.predict(features_test)\n",
    "y_pred = np.argmax(y_pred_prob, axis=1)\n",
    "\n",
    "# 输出分类报告\n",
    "report = classification_report(np.argmax(labels_test_one_hot, axis=1), y_pred)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cffa685f-166d-4953-ba8e-80b6b3fccda0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
