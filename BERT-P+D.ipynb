{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c658d8d-e841-467c-8536-c333207c92aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      ProjectID                                    RequirementText _class_\n",
      "0             1  The system shall refresh the display every 60 ...      PE\n",
      "1             1  The application shall match the color of the s...      LF\n",
      "2             1  If projected  the data must be readable.  On a...      US\n",
      "3             1  The product shall be available during normal b...       A\n",
      "4             1  If projected  the data must be understandable....      US\n",
      "...         ...                                                ...     ...\n",
      "2052          9  The database may trade off fidelity through ca...      FT\n",
      "2053          9  The API shall have master topology replicating...      FT\n",
      "2054          9  The system must parse, filter, transform and s...      FT\n",
      "2055          9  The application shall employ real-user monitor...      FT\n",
      "2056          9  The software should apply graceful degradation...      FT\n",
      "\n",
      "[2057 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import arff as liacarff\n",
    "\n",
    "# 加载 ARFF 文件\n",
    "with open('PROMISE_DOSSPRE_OLD_3.arff', 'r') as f:\n",
    "    data_dict = liacarff.load(f)\n",
    "\n",
    "# 提取数据\n",
    "data = data_dict['data']\n",
    "\n",
    "# 转换为 DataFrame\n",
    "df = pd.DataFrame(data, columns=[attr[0] for attr in data_dict['attributes']])\n",
    "df['ProjectID'] = df['ProjectID'].astype(int)  # 将 ProjectID 列转换为整数类型\n",
    "\n",
    "# 显示 DataFrame\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "16aa2021-74e1-48cc-bb8f-f76b4737dc13",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['RequirementText']\n",
    "y = df['_class_']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4526efab-c12e-4703-8eb5-8d6154853cf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from transformers import BertTokenizer, TFBertForSequenceClassification\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 使用 LabelEncoder 将字符串类别映射到整数\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "y_val_encoded = label_encoder.transform(y_val)\n",
    "\n",
    "# 使用 BertTokenizer 加载预训练的 BERT 模型\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "train_encodings = tokenizer(X_train.tolist(), truncation=True, padding=True, max_length=128, return_tensors='tf')\n",
    "val_encodings = tokenizer(X_val.tolist(), truncation=True, padding=True, max_length=128, return_tensors='tf')\n",
    "\n",
    "# 创建 TensorFlow Dataset\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    dict(train_encodings),\n",
    "    y_train_encoded\n",
    "))\n",
    "\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    dict(val_encodings),\n",
    "    y_val_encoded\n",
    "))\n",
    "\n",
    "# 构建 BERT 模型\n",
    "model = TFBertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=len(df['_class_'].unique()))\n",
    "\n",
    "# 编译模型\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=5e-5)\n",
    "model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# 训练模型\n",
    "num_epochs = 3\n",
    "model.fit(train_dataset.shuffle(1000).batch(8), epochs=num_epochs)\n",
    "\n",
    "# 评估模型\n",
    "val_preds = model.predict(val_dataset.batch(8))\n",
    "val_preds = tf.argmax(val_preds.logits, axis=1).numpy()\n",
    "val_labels = y_val_encoded\n",
    "\n",
    "accuracy = accuracy_score(val_labels, val_preds)\n",
    "print(f\"Accuracy on validation set: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32103cba-7746-48ba-bc0e-0067ba06a79f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
