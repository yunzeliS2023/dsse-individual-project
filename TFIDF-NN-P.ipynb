{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c658d8d-e841-467c-8536-c333207c92aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     ProjectID                                    RequirementText _class_\n",
      "0            1  The system shall refresh the display every 60 ...      PE\n",
      "1            1  The application shall match the color of the s...      LF\n",
      "2            1  If projected  the data must be readable.  On a...      US\n",
      "3            1  The product shall be available during normal b...       A\n",
      "4            1  If projected  the data must be understandable....      US\n",
      "..         ...                                                ...     ...\n",
      "965         48  Registered User must be able to maintain his/h...       F\n",
      "966         48  The entire website must be user-friendly and e...      US\n",
      "967         48  The system shall support up to 10000 simultane...      PE\n",
      "968         48  The website must provide highest degree of sec...      SE\n",
      "969         49  The software application should be easily tran...      PO\n",
      "\n",
      "[970 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import arff as liacarff\n",
    "\n",
    "# 加载 ARFF 文件\n",
    "with open('PROMISE_exp.arff', 'r') as f:\n",
    "    data_dict = liacarff.load(f)\n",
    "\n",
    "# 提取数据\n",
    "data = data_dict['data']\n",
    "\n",
    "# 转换为 DataFrame\n",
    "df = pd.DataFrame(data, columns=[attr[0] for attr in data_dict['attributes']])\n",
    "df['ProjectID'] = df['ProjectID'].astype(int)  # 将 ProjectID 列转换为整数类型\n",
    "\n",
    "# 显示 DataFrame\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "59f1598c-1b5e-42a4-bf9b-93507a98a49d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/li/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/li/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/li/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ProjectID                                    RequirementText _class_\n",
      "0          1       system shall refresh display every 60 second      PE\n",
      "1          1  application shall match color schema set forth...      LF\n",
      "2          1  projected data must readable 10x10 projection ...      US\n",
      "3          1  product shall available normal business hour l...       A\n",
      "4          1  projected data must understandable 10x10 proje...      US\n"
     ]
    }
   ],
   "source": [
    "# DATA PREPROCESSING\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import re\n",
    "import string\n",
    "\n",
    "# 下载NLTK的停用词和词性标注器数据\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "# lower\n",
    "df['RequirementText'] = df['RequirementText'].str.lower()\n",
    "\n",
    "# Remove punctuation, leading and trailing spaces\n",
    "df['RequirementText'] = df['RequirementText'].apply(lambda x: re.sub(f\"[{re.escape(string.punctuation)}]\", \"\", x.strip()))\n",
    "\n",
    "# 分词\n",
    "df['RequirementText'] = df['RequirementText'].apply(word_tokenize)\n",
    "\n",
    "# stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "df['RequirementText'] = df['RequirementText'].apply(lambda x: [word for word in x if word not in stop_words])\n",
    "\n",
    "# stemming\n",
    "# stemmer = PorterStemmer()\n",
    "# df['RequirementText'] = df['RequirementText'].apply(lambda x: [stemmer.stem(word) for word in x])\n",
    "\n",
    "# lemmatization\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "df['RequirementText'] = df['RequirementText'].apply(lambda x: [lemmatizer.lemmatize(word) for word in x])\n",
    "\n",
    "# 合并词语为字符串\n",
    "df['RequirementText'] = df['RequirementText'].apply(lambda x: ' '.join(x))\n",
    "\n",
    "# Replace multiple spaces with a single space\n",
    "df['RequirementText'] = df['RequirementText'].apply(lambda x: re.sub(' +', ' ', x))\n",
    "\n",
    "# 移除整个列中每个字符串首尾的全部空格\n",
    "df['RequirementText'] = df['RequirementText'].str.strip()\n",
    "\n",
    "# 查看处理后的数据集\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2df99007-ddfa-4b3a-99b6-e0f687b55ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e3d7057a-3221-46a4-95e6-66a2af495211",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "y = df['_class_']\n",
    "X = df['RequirementText']\n",
    "\n",
    "# 假设 X 是特征，y 是目标变量（类别标签）\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "671deca6-85fe-4be4-ab09-3c1ee057bbf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "# 使用TfidfVectorizer进行转换\n",
    "ngram_range = (1,2)\n",
    "min_df = 0.01 # ignore terms that appear in less than 1% of the documents\n",
    "max_df = 0.8 # ignore terms that appear in more than 80% of the documents\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(encoding='utf-8',\n",
    "                        ngram_range=ngram_range,\n",
    "                        stop_words=None,\n",
    "                        lowercase=False,\n",
    "                        max_df=max_df,\n",
    "                        min_df=min_df,\n",
    "                        norm='l2',\n",
    "                        sublinear_tf=True)\n",
    "\n",
    "features_train = tfidf_vectorizer.fit_transform(X_train).toarray()\n",
    "labels_train = y_train\n",
    "features_test = tfidf_vectorizer.transform(X_test).toarray()\n",
    "labels_test = y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7165f44e-6a30-4d90-a751-2958bbbc34be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "55/55 [==============================] - 1s 5ms/step - loss: 2.3851 - accuracy: 0.3471 - val_loss: 2.2159 - val_accuracy: 0.4536\n",
      "Epoch 2/100\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 1.9907 - accuracy: 0.4582 - val_loss: 1.7840 - val_accuracy: 0.4536\n",
      "Epoch 3/100\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 1.7169 - accuracy: 0.4582 - val_loss: 1.6776 - val_accuracy: 0.4536\n",
      "Epoch 4/100\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 1.6127 - accuracy: 0.4582 - val_loss: 1.5893 - val_accuracy: 0.4536\n",
      "Epoch 5/100\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 1.5215 - accuracy: 0.4605 - val_loss: 1.5078 - val_accuracy: 0.4536\n",
      "Epoch 6/100\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 1.4308 - accuracy: 0.4926 - val_loss: 1.4387 - val_accuracy: 0.4845\n",
      "Epoch 7/100\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 1.3414 - accuracy: 0.5292 - val_loss: 1.3646 - val_accuracy: 0.5670\n",
      "Epoch 8/100\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 1.2568 - accuracy: 0.5853 - val_loss: 1.3128 - val_accuracy: 0.5876\n",
      "Epoch 9/100\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 1.1760 - accuracy: 0.6231 - val_loss: 1.2826 - val_accuracy: 0.5773\n",
      "Epoch 10/100\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 1.1058 - accuracy: 0.6438 - val_loss: 1.2258 - val_accuracy: 0.5979\n",
      "Epoch 11/100\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 1.0462 - accuracy: 0.6804 - val_loss: 1.2313 - val_accuracy: 0.5979\n",
      "Epoch 12/100\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 0.9955 - accuracy: 0.6964 - val_loss: 1.2074 - val_accuracy: 0.5979\n",
      "Epoch 13/100\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 0.9453 - accuracy: 0.7033 - val_loss: 1.1943 - val_accuracy: 0.6082\n",
      "Epoch 14/100\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 0.9015 - accuracy: 0.7205 - val_loss: 1.1799 - val_accuracy: 0.6289\n",
      "Epoch 15/100\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 0.8618 - accuracy: 0.7365 - val_loss: 1.1586 - val_accuracy: 0.6289\n",
      "Epoch 16/100\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 0.8240 - accuracy: 0.7480 - val_loss: 1.1624 - val_accuracy: 0.6289\n",
      "Epoch 17/100\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 0.7873 - accuracy: 0.7583 - val_loss: 1.1631 - val_accuracy: 0.6495\n",
      "Epoch 18/100\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 0.7556 - accuracy: 0.7629 - val_loss: 1.1422 - val_accuracy: 0.6495\n",
      "Epoch 19/100\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 0.7229 - accuracy: 0.7835 - val_loss: 1.1363 - val_accuracy: 0.6495\n",
      "Epoch 20/100\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 0.6920 - accuracy: 0.7961 - val_loss: 1.1441 - val_accuracy: 0.6495\n",
      "Epoch 21/100\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 0.6639 - accuracy: 0.8087 - val_loss: 1.1581 - val_accuracy: 0.6598\n",
      "Epoch 22/100\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 0.6373 - accuracy: 0.8190 - val_loss: 1.1472 - val_accuracy: 0.6598\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.1363 - accuracy: 0.6495\n",
      "Test Accuracy: 0.6494845151901245\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         3\n",
      "           1       0.76      0.89      0.82        44\n",
      "           2       0.00      0.00      0.00         2\n",
      "           3       0.00      0.00      0.00         1\n",
      "           4       0.67      0.40      0.50         5\n",
      "           5       0.00      0.00      0.00         2\n",
      "           6       0.38      0.38      0.38         8\n",
      "           7       0.56      0.71      0.63         7\n",
      "           8       0.00      0.00      0.00         1\n",
      "           9       0.00      0.00      0.00         2\n",
      "          10       0.64      0.69      0.67        13\n",
      "          11       0.42      0.56      0.48         9\n",
      "\n",
      "    accuracy                           0.65        97\n",
      "   macro avg       0.29      0.30      0.29        97\n",
      "weighted avg       0.58      0.65      0.61        97\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/li/dsse/indi/indi/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/li/dsse/indi/indi/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/li/dsse/indi/indi/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "feature_names = tfidf_vectorizer.get_feature_names_out()\n",
    "input_dimension = len(feature_names)\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "labels_train_encoded = label_encoder.fit_transform(labels_train)\n",
    "labels_test_encoded = label_encoder.transform(labels_test)\n",
    "\n",
    "labels_train_one_hot = to_categorical(labels_train_encoded)\n",
    "labels_test_one_hot = to_categorical(labels_test_encoded)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(24, input_dim=input_dimension, activation='relu'))\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dense(12, activation='softmax'))\n",
    "\n",
    "# 创建 EarlyStopping 回调\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "\n",
    "# 编译模型\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# 训练模型，并使用 EarlyStopping 回调\n",
    "history = model.fit(features_train, labels_train_one_hot, epochs=100, batch_size=16, \n",
    "                    validation_data=(features_test, labels_test_one_hot),\n",
    "                    callbacks=[early_stopping])\n",
    "\n",
    "accuracy = model.evaluate(features_test, labels_test_one_hot)[1]\n",
    "print(\"Test Accuracy:\", accuracy)\n",
    "\n",
    "y_pred_prob = model.predict(features_test)\n",
    "y_pred = np.argmax(y_pred_prob, axis=1)\n",
    "\n",
    "report = classification_report(np.argmax(labels_test_one_hot, axis=1), y_pred)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0f0708dd-4660-4b4b-89de-eefd3792671b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 5 Complete [00h 00m 07s]\n",
      "val_accuracy: 0.7388315995534261\n",
      "\n",
      "Best val_accuracy So Far: 0.7525773048400879\n",
      "Total elapsed time: 00h 00m 37s\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.9982 - accuracy: 0.7629\n",
      "Test Accuracy (Best Model): 0.7628865838050842\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.67      0.80         3\n",
      "           1       0.81      0.98      0.89        44\n",
      "           2       0.00      0.00      0.00         2\n",
      "           3       0.00      0.00      0.00         1\n",
      "           4       0.50      0.60      0.55         5\n",
      "           5       0.50      0.50      0.50         2\n",
      "           6       0.75      0.38      0.50         8\n",
      "           7       0.83      0.71      0.77         7\n",
      "           8       0.00      0.00      0.00         1\n",
      "           9       1.00      0.50      0.67         2\n",
      "          10       0.71      0.77      0.74        13\n",
      "          11       0.67      0.67      0.67         9\n",
      "\n",
      "    accuracy                           0.76        97\n",
      "   macro avg       0.56      0.48      0.51        97\n",
      "weighted avg       0.74      0.76      0.74        97\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/li/dsse/indi/indi/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/li/dsse/indi/indi/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/li/dsse/indi/indi/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from kerastuner.tuners import RandomSearch\n",
    "from kerastuner.engine.hyperparameters import HyperParameters\n",
    "\n",
    "# 定义模型构建函数\n",
    "def build_model(hp):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units=hp.Int('units_1', min_value=8, max_value=256, step=8),\n",
    "                    activation='relu', input_dim=input_dimension))\n",
    "    model.add(Dense(units=hp.Int('units_2', min_value=8, max_value=256, step=8),\n",
    "                    activation='relu'))\n",
    "    model.add(Dense(12, activation='softmax'))\n",
    "    \n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# 创建 EarlyStopping 回调\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "\n",
    "# 创建调优器\n",
    "tuner = RandomSearch(\n",
    "    build_model,\n",
    "    objective='val_accuracy',\n",
    "    max_trials=5,  # 试验的次数\n",
    "    executions_per_trial=3,  # 每个试验运行的次数\n",
    "    directory='my_tuning_dir',  # 存储结果的目录\n",
    "    project_name='my_neural_network_tuning'\n",
    ")\n",
    "\n",
    "# 运行调优\n",
    "tuner.search(features_train, labels_train_one_hot, epochs=100, batch_size=16, \n",
    "             validation_data=(features_test, labels_test_one_hot),\n",
    "             callbacks=[early_stopping])\n",
    "\n",
    "# 获取最佳模型\n",
    "best_model = tuner.get_best_models(num_models=1)[0]\n",
    "\n",
    "# 评估最佳模型\n",
    "accuracy = best_model.evaluate(features_test, labels_test_one_hot)[1]\n",
    "print(\"Test Accuracy (Best Model):\", accuracy)\n",
    "\n",
    "# 预测最佳模型的输出\n",
    "y_pred_prob = best_model.predict(features_test)\n",
    "y_pred = np.argmax(y_pred_prob, axis=1)\n",
    "\n",
    "# 输出分类报告\n",
    "report = classification_report(np.argmax(labels_test_one_hot, axis=1), y_pred)\n",
    "print(report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59a2e964-a49a-4b32-b3a5-75b626e4de52",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39924618-c88f-46cc-b2d6-c3794c3e2d8e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
